### DataFrame描述

DataFrame是一个【表格型】的数据结构，可以看做是【由Series组成的字典】（共用同一个索引）。DataFrame由按一定顺序排列的多列数据组成。设计初衷是将Series的使用场景从一维拓展到多维。DataFrame既有行索引，也有列索引

### 

### DataFrame的创建

```python
（1）字典创建    
# DataFrame以字典的键作为每一【列】的名称，以字典的值（一个数组）作为每一列。
# 若传入的列与字典的键不匹配，则相应的值为NaN。
df = DataFrame({'A':[1,2,3],'B':[2,3,4],'C':[5,6,7]})
df
>>>  A B C
---------------
0    1 2 5
1    2 3 6
2    3 4 7

(2) 列表或ndarray数组创建
data=np.random.randint(0,150,size=(4,4))
columns=['语文','数学','英语','理综']
index=['张三','李四','王五','赵六']
dd = DataFrame(data=data,columns=columns,index=index)

```

##### 多层索引DataFrame创建

```python
方法一:
data = np.random.randint(0,150, size=(8,6))
index = [['一班','一班','一班','一班','二班','二班','二班','二班'],['张三','李四','王五','赵六', '王二麻子','王小二','小明','隔壁老王']]
columns = [['期中','期中','期中','期末','期末','期末'], ['语文','数学','英语','语文','数学','英语']]
df = DataFrame(data=data, index=index,columns=columns)

方法二:
data = np.random.randint(0,150, size=(6,6))
index = pd.MultiIndex.from_product([['一班','二班',],['张三','李四','王五']])
columns = pd.MultiIndex.from_product([['期中','期末'], ['语文','数学','英语']])
df = DataFrame(data=data, index=index,columns=columns)
```

![Dataframe1](C:\Users\Administrator\Desktop\数据分析总结\photo\Dataframe1.png)



### DataFrame属性

```python
DataFrame属性：values、columns、index、shape

dd.values   ----数值--data（numpy的二维数组）
>>>array([[ 19, 121, 135,   6],
       [ 31,  60,   9, 133],
       [ 95,  85, 104,  21],
       [ 35,  71, 142,  95]])

dd.colcumns ---列对象
>>>Index(['语文', '数学', '英语', '理综'], dtype='object')

dd.index ----行对象
>>>Index(['张三', '李四', '王五', '赵六'], dtype='object')

dd.shape
>>>(4, 4)

```

### 索引

##### 一层索引

(1) 对列进行索引

- 通过类似字典的方式
- 通过属性的方式

可以将DataFrame的列获取为一个Series。返回的Series拥有原DataFrame相同的索引，且name属性也已经设置好了，就是相应的列名。

```python

•行索引：index
•列索引：columns
•值：values（numpy的二维数组）
    
      语文   数学    英语    理综
张三   150   150     150    300
李四   80    120     102    250
王五   80    99      110    199
赵六   67    101     77     220



行索引
#获取的是series                    #获取的是DataFrame表
dd.loc['张三']                     dd.loc[['张三']]
>>>语文    150                     >>>  语文   数学   英语   理综
   数学    150                     张三  150   150    150    300
   英语    150                    
   理综    300                    
   Name: 张三, dtype: int64       

 
列索引        
#获取的是Series                #获取的是Dataframe表
dd['语文']                     dd[['语文'，'英语']]  #提取语文和英语成绩表
>>>张三    136                 >>>  语文   英语
李四     52                    张三  150   150
王五     10                    李四  80    102
赵六     42                    王五  80    110
                               赵六  67    77
#隐式索引-----行索引
dd.iloc[[3,1]]   # 3表示第四行所有数据，1表示第二行所有数据
>>>返回表  

dd.iloc[3,1]     # 第四行第二列的数据
>>>返回数值


元素索引
#取张三的数学成绩
#行索引   行--列
dd.loc['张三','数学']
df.loc['张三'] ['数学']
#列索引   列--行
dd['数学']['张三']

```

##### 多层索引

```python
【极其重要】推荐使用loc()函数
df.loc['一班', '张三']

#行操作
df.loc['一班','张三']['期中','英语']
# 列操作
df['期中','英语']['一班', '张三']
```

##### stack()和unstack():行列索引转换

```python
#stack() 将列索引变成行索引;
#level=0---从上到下,指定第一个列索引转成行索引,插入在行的最右边
# unstack()将行索引变成列索引; 
#level=0---从左到右,第一个行索引;fill_value=0 ---将NaN的值设为0
df.unstack(level=0,fill_value=0)
```



### DataFrame运算

 DataFrame之间的运算同Series一样：

- 在运算中自动对齐不同索引的数据

- 如果索引不对应，则补NaN

- ```
  df1 = DataFrame(data=np.random.randint(0,150,size=(4,4)), index=['张三', '李四', '王五', '赵六'], columns=['语文','数学','英语','理综'])
  ```

  ​

  ![num1](C:\Users\Administrator\Desktop\数据分析总结\photo\num1.png)

  ```python

  df2 = DataFrame(data=np.random.randint(0,150,size=(5,4)), index=['张三', '李四', '王五', '赵六','Michael'], columns=['语文','数学','英语','理综'])

  ```

  ![num2](C:\Users\Administrator\Desktop\数据分析总结\photo\num2.png)

  ```python
  df1 + df2
  ```

  ![QQ截图20180714164549](C:\Users\Administrator\Desktop\数据分析总结\photo\QQ截图20180714164549.png)


```python

#将Michael原来的成绩打印出来
df1.add(df2,fill_value=0, axis='index')

```

![num3](C:\Users\Administrator\Desktop\数据分析总结\photo\num3.png)



### 过滤

##### dropna()

```python
axis ---轴
#dropna默认删除含有NaN的行
df.dropna()
#删除含有NaN的列
df.dropna(axis=1,inplace=True)     #inplace=True是否更改数据

#当整列都为NaN的时,删除该列
df.dropna(axis=1,how='all')
```

![NaN](C:\Users\Administrator\Desktop\数据分析总结\photo\NaN.png)

```python
#填充函数--fillna
df.fillna(value=50,axis=1)   #把NaN全部改为50

# 使用前一列的数据来填充
df.fillna(method='ffill', axis=1)  #NaN前一列的数据填充,该列可以不全为NaN

# 使用后一列的数据来填充
df.fillna(method='bfill', axis=1)  #NaN后一列的数据填充,该列可以不全为NaN
```

##### 自定义过滤

```python
#标准差的平均值
row_std_mean = df2.std(axis = 1).mean()
#过滤
cond3 = df2.std(axis = 1) > row_std_mean*2.5
#获取行索引
large_std_index = df2[cond3].index
#删除行索引
df3 = df2.drop(large_std_index)
```







### 改

##### fillna() ---将NAN --> 0

```python
freq_df = pd.merge(left=target_, right=freq_df, how='left').fillna(0).reset_index(drop=True)
```









![source](D:\BaiduNetdiskDownload\数据分析总结\photo\source.png)

```python
#行索引
df.loc['张三', '英语'] = None
#列索引
df['英语','张三'] = None
```

![after](D:\BaiduNetdiskDownload\数据分析总结\photo\after.png)

##### set_index():设置为行索引

```python
#DataFrame.set_index()
df.set_index('Python',inplace=True)   #将python列设置为行索引,原来的人名则删除了
```

##### reset_index():索引变成列

![reset1](D:\BaiduNetdiskDownload\数据分析总结\photo\reset1.png)

```python
#Series.reset_index()---df中含有的Java属性
df.Java.reset_index()
```

![reset2](D:\BaiduNetdiskDownload\数据分析总结\photo\reset2.png)





##### replace()函数：替换元素

使用replace()函数,对 values 进行替换操作

```python
#修改张三的语文和数学成绩
a={148:120,124:34}   #字典----要替换的数据:替换的数据
df.replace(a)

```

##### rename()函数：替换索引

![rename1](D:\BaiduNetdiskDownload\数据分析总结\photo\rename1.png)

```python
def cols(x):
    if x == 'PHP':
        return 'php'
    if x == 'Python':
        return '大蟒蛇'
    else:
        return x
    
inds = {'张三':'Zhang Sir','木兰':'MissLan'}

df.rename(index = inds,columns=cols)
```

![rename2](D:\BaiduNetdiskDownload\数据分析总结\photo\rename2.png)



##### to_datetime():时间类型

```python
#DataFrame的times这列转换成时间类型为:2011-3-12
df.times = pd.to_datetime(df.times)
```



##### cumsum():累加函数

```python
n = np.array([1,2,3,4,5,6])
n.cumsum()
>>>array([ 1,  3,  6, 10, 15, 21])
#按照时间累加,时间是行索引
plt.plot(ele_amt.cumsum())   #画出曲线图


```

#### 排序

##### sort_values():值排序

```python
#按照时间的顺序进行排序,df中的times列
df.sort_values('times',inplace=True)  #按照数值大小排序
```

##### take():行排序

一般配合np.random.permutation()函数生成随机排列

![take1](D:\BaiduNetdiskDownload\数据分析总结\photo\take1.png)

```python
df.take([3,2,0])
```

![take2](D:\BaiduNetdiskDownload\数据分析总结\photo\take2.png)

```python
indices = np.random.permutation(4)
>>>[2,3,1,0]
df.take(indice)  #生成随机的行排列
```





### 增 

##### concat():级联

```python
#使用函数创建两个DataFrame
#和数组np.concatenate一样，优先增加行数（默认axis=0）
pd.concat((df1,df2))
##级连会把该方向上索引完全相同的元素放在一行（一列），index/columns在级联时可以重复
pd.concat((df1,df2), axis=1)   #增加列，变成4行6列，没有数据的用NaN填充
#ignore_index，重新索引
pd.concat((df1,df2) ,ignore_index=True)  #行索引重新排列

不匹配级联:  
#不匹配指的是级联的维度的索引不一致
•外连接：补NaN（默认模式）
pd.concat((df1,df2), join='outer',axis=0)#默认axis=0,行连接

•内连接：只连接匹配的项
pd.concat((df1,df2), join='inner')

•连接指定轴 join_axes
#轴为：df1.columns 对象，补NaN
pd.concat((df1,df2), join_axes=[df1.columns])   #拼接后的列为df1的列
```



##### append()函数: 行合并

![append1](D:\BaiduNetdiskDownload\数据分析总结\photo\append1.png)

```python
dd = DataFrame(data=np.random.randint(80,150,size=(1,3)),index=['张三'],columns=['Python','Java','PHP'])

```

![append2](D:\BaiduNetdiskDownload\数据分析总结\photo\append2.png)

```
df.append(dd)
```

![append3](D:\BaiduNetdiskDownload\数据分析总结\photo\append3.png)



##### merge():列合并

一对一：

![merge1](D:\BaiduNetdiskDownload\数据分析总结\photo\merge1.png)

```python
pd.merge(df1,df2)
```

![merge2](D:\BaiduNetdiskDownload\数据分析总结\photo\merge2.png)

多对一：

![merge3](D:\BaiduNetdiskDownload\数据分析总结\photo\merge3.png)

```
pd.merge(df1,df2)
```

![merge4](D:\BaiduNetdiskDownload\数据分析总结\photo\merge4.png)

多对多：

![merge5](D:\BaiduNetdiskDownload\数据分析总结\photo\merge5.png)

```python
pd.merge(df1,df2)
```

![merge6](D:\BaiduNetdiskDownload\数据分析总结\photo\merge6.png)



多个key-----key为列属性

- 使用 on= 显式指定哪一列为key,当有多个key相同时使用

  ![key1](D:\BaiduNetdiskDownload\数据分析总结\photo\key1.png)

```python
pd.merge(df1,df2,on='name', suffixes=['_a', '_b'])   #后缀名
```

![key2](D:\BaiduNetdiskDownload\数据分析总结\photo\key2.png)





- 使用left_on和right_on指定左右两边的列作为key，当左右两边的key都不相等时使用

![key3](D:\BaiduNetdiskDownload\数据分析总结\photo\key3.png)

```python
pd.merge(df1,df2, left_on='name',right_on='名字')
```

![key4](D:\BaiduNetdiskDownload\数据分析总结\photo\key4.png)



- 当左边的列跟右边的index相同时，使用right_index=True

![key5](D:\BaiduNetdiskDownload\数据分析总结\photo\key5.png)

```python
pd.merge(df1,df2, left_on='age',right_index=True)
```

![key6](D:\BaiduNetdiskDownload\数据分析总结\photo\key6.png)



##### map()函数：新添加一列

map()也有映射关系，新添加一列，根据现存的那一列进行添加

![map1](D:\BaiduNetdiskDownload\数据分析总结\photo\map1.png)

```python
v = {75:90,80:100,146:166,35:55}
df['Go'] = df['Python'].map(v)
```

![map2](D:\BaiduNetdiskDownload\数据分析总结\photo\map2.png)

map()也可以使用 lambda函数,函数

```python
def mp(x):
    #复杂的条件
    if x <51:
        return '不及格'
    else:
        return '优秀'
#函数    
df['score'] = df['C'].map(mp)

#lambda函数
df['C'] = df['Go'].map(lambda x : x -40)
```

![map3](D:\BaiduNetdiskDownload\数据分析总结\photo\map3.png)









### 删

```python
#创建一个DataFrame
data = np.random.randint(0,150,size = (4,4))
columns=['Python','Java','PHP','HTML']
index = ['张三','旭日','阳刚','木兰']
df = DataFrame(data=data,columns=columns,index = index)
```

![drop1](D:\BaiduNetdiskDownload\数据分析总结\photo\drop1.png)

##### drop():删除指定的一列或行

```python
#删除HTML这列
df.drop(columns='HTML',inplace=True)
```

![drop2](D:\BaiduNetdiskDownload\数据分析总结\photo\drop2.png)

```python
df.drop(index='张三',inplace=True)  #删除'张三'这一行
df.drop(['张三','木兰])  #删除'张三'和'木兰'两行数据
```



#### 删除重复元素

##### df.duplicated()函数

df.duplicated()函数,检测重复(数据全都一样)的行,第一次出现则为False,不是第一次出现则为True

返回的是dtype: bool

```python
#搭配使用 np.logical_not()--逻辑非;np.logical_and()--逻辑与;np.logical_or()--逻辑或
a = df.duplicated()
df[np.logical_not(a)]
```



##### df.drop_duplicates()函数

```python
df.drop_duplicates()删除重复的行
```





### 查

##### 与Series索引结合

```python
#查看老兵主要支持谁：DISABLED VETERAN  
cond = ele['contbr_occupation'] == 'DISABLED VETERAN'
>>>返回的是false或者true ----series对象
veteran = ele[cond]
>>>返回的是DataFrame对象
```



##### describe()函数: 

查看每一列的描述性统计量

```python
df.describe()  # 查看包括 count,mean,std,min,max 每一列的统计数值
```



##### std()函数:标准差

使用std()函数可以求得DataFrame对象每一列的标准差

```
df.std()
```



##### unique()函数:查询元素

使用np.unique()函数查看columns中party这一列中包含有哪些元素

```python
df['party'].unique()
>>>array(['Republican', 'Democrat', 'Reform', 'Libertarian'], dtype=object)
```



##### value_counts():

value_counts()函数 ,统计party列中各个元素出现的次数

```python
df['party'].value_counts()   #或 df.party.values_counts()
>>>Democrat       292400
   Republican     237575
   Reform           5364
   Libertarian       702
   Name: party, dtype: int64
```



##### query():条件查询

```python
#通过ele.query("查询条件来查找捐献人职业")
ele.query("cand_nm == 'Obama, Barack' and contb_receipt_amt == 1944042.43")
>>>返回DataFrame对象
```



#### 聚合操作

![Dataframe1](D:\BaiduNetdiskDownload\数据分析总结\photo\Dataframe1.png)

```python
•【小技巧】聚合的时候，axis等于哪一个，哪一个就保留。
所谓的聚合操作：平均数mean，方差std，最大值max，最小值min……
# axis=0表示选择的是行，level=1选这是第二个，----保留行中的第二个
df.mean(axis=0, level=1)
# axis=0表示选择的是行，level=1选这是第二个，----保留行中的第一个
df.mean(axis=0, level=0)
```

```python
df.mean(axis=0,level=1) #平均值
```

![DataFrame2](D:\BaiduNetdiskDownload\数据分析总结\photo\DataFrame2.png)

```
df.max()
```

![max](D:\BaiduNetdiskDownload\数据分析总结\photo\max.png)

##### groupby()：数据处理

数据分类处理的核心:groupba()函数

![groupby1](D:\BaiduNetdiskDownload\数据分析总结\photo\groupby1.png)

```python
#条件:一层行索引,一层列索引
cc = df.groupby(['color'])[['weight']].sum()  # 扩展 mean(),max(),min(),std()方差
cc
```

![groupby2](D:\BaiduNetdiskDownload\数据分析总结\photo\groupby2.png)



##### merge():列合并

##### concat():级联









